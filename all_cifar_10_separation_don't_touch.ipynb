{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Separation of CIFAR-10 Images\n",
        "\n",
        "The model takes as input an image created by averaging two random samples from CIFAR-10 and is tasked with predicting the categories of the two components.\n",
        "\n",
        "The first image belongs to the first five categories (airplane, automobile, bird, cat, deer), while the second belongs to the remaining categories (dog, frog, horse, ship, truck). The model must return two labels, each within a range of five possible values.\n",
        "\n",
        "The evaluation metric for the model is as follows: calculate the classification accuracy for the two component images and then compute their average.\n",
        "\n",
        "The metric should be evaluated on 10,000 inputs generated from test data. Repeat the calculation 10 times and measure the standard deviation, which must be reported.\n",
        "\n",
        "A data generator and some examples are provided below."
      ],
      "metadata": {
        "id": "mE7oyG0wv6e0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preparation"
      ],
      "metadata": {
        "id": "USdmzjiO0W6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "iHjnh5XP0Sq4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
        "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
        "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
        "assert cifar10_y_train.shape == (50000, 1)\n",
        "assert cifar10_y_test.shape == (10000, 1)\n",
        "\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
        "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
      ],
      "metadata": {
        "id": "yRYiW2ipukZF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us split the images in two groups, according to their label."
      ],
      "metadata": {
        "id": "ZkiGnU4d0k4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "cond_1 = cifar10_y_train[:,0] < 5\n",
        "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
        "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
        "\n",
        "cond_2 = cifar10_y_train[:,0] >= 5\n",
        "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
        "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
        "\n",
        "cond_1_test = cifar10_y_test[:,0] < 5\n",
        "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
        "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
        "\n",
        "cond_2_test = cifar10_y_test[:,0] >= 5\n",
        "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
        "cifar10_y_test_2 = cifar10_y_test[cond_2_test]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Dpey42Vo07Yb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3f2e8885-b71f-470f-e5b2-1f61758d3390"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncond_1 = cifar10_y_train[:,0] < 5\\ncifar10_x_train_1 = cifar10_x_train[cond_1]\\ncifar10_y_train_1 = cifar10_y_train[cond_1]\\n\\ncond_2 = cifar10_y_train[:,0] >= 5\\ncifar10_x_train_2 = cifar10_x_train[cond_2]\\ncifar10_y_train_2 = cifar10_y_train[cond_2]\\n\\ncond_1_test = cifar10_y_test[:,0] < 5\\ncifar10_x_test_1 = cifar10_x_test[cond_1_test]\\ncifar10_y_test_1 = cifar10_y_test[cond_1_test]\\n\\ncond_2_test = cifar10_y_test[:,0] >= 5\\ncifar10_x_test_2 = cifar10_x_test[cond_2_test]\\ncifar10_y_test_2 = cifar10_y_test[cond_2_test]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data into train and validation sets\n",
        "val_split = 0.1\n",
        "num_val_samples = int(cifar10_x_train.shape[0] * val_split)\n",
        "\n",
        "cifar10_x_val = cifar10_x_train[:num_val_samples]\n",
        "cifar10_y_val = cifar10_y_train[:num_val_samples]\n",
        "\n",
        "cifar10_x_train = cifar10_x_train[num_val_samples:]\n",
        "cifar10_y_train = cifar10_y_train[num_val_samples:]\n",
        "\n",
        "# Separate data into two groups for training\n",
        "cond_1_train = cifar10_y_train[:, 0] < 5\n",
        "cifar10_x_train_1 = cifar10_x_train[cond_1_train]\n",
        "cifar10_y_train_1 = cifar10_y_train[cond_1_train]\n",
        "\n",
        "cond_2_train = cifar10_y_train[:, 0] >= 5\n",
        "cifar10_x_train_2 = cifar10_x_train[cond_2_train]\n",
        "cifar10_y_train_2 = cifar10_y_train[cond_2_train]\n",
        "\n",
        "# Separate validation data into two groups\n",
        "cond_1_val = cifar10_y_val[:, 0] < 5\n",
        "cifar10_x_val_1 = cifar10_x_val[cond_1_val]\n",
        "cifar10_y_val_1 = cifar10_y_val[cond_1_val]\n",
        "\n",
        "cond_2_val = cifar10_y_val[:, 0] >= 5\n",
        "cifar10_x_val_2 = cifar10_x_val[cond_2_val]\n",
        "cifar10_y_val_2 = cifar10_y_val[cond_2_val]\n",
        "\n",
        "# Separate test data into two groups\n",
        "cond_1_test = cifar10_y_test[:, 0] < 5\n",
        "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
        "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
        "\n",
        "cond_2_test = cifar10_y_test[:, 0] >= 5\n",
        "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
        "cifar10_y_test_2 = cifar10_y_test[cond_2_test]\n"
      ],
      "metadata": {
        "id": "NS4253lo913D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can define the generator. The input consists of two datasets (X1,X2), their corresponding labels (Y1,Y2), and a batch size.\n",
        "\n",
        "The generator returns (x_data,y_data), where:\n",
        "* x_data is a batch of images obtained by averaging random samples from X1 and X2.\n",
        "* y_data is a pair of batches of labels corresponding to the component images, expressed in categorical format."
      ],
      "metadata": {
        "id": "qmLYNuR-0s0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def datagenerator(X1,X2,Y1,Y2,batchsize):\n",
        "  size1 = X1.shape[0]\n",
        "  size2 = X2.shape[0]\n",
        "  Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
        "  Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
        "\n",
        "  while True:\n",
        "    num1 = np.random.randint(0, size1, batchsize)\n",
        "    num2 = np.random.randint(0, size2, batchsize)\n",
        "    x_data = (X1[num1] + X2[num2]) / 2.0\n",
        "    y_data = (Y1_cat[num1],Y2_cat[num2])\n",
        "\n",
        "    yield x_data, y_data"
      ],
      "metadata": {
        "id": "7Y5Zpv5fw2hd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let us instantiate a generator on Cifar10 with batchsize=1, and let's see its behaviour."
      ],
      "metadata": {
        "id": "Z9lf3TuP2pdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,1)"
      ],
      "metadata": {
        "id": "29TldJ6-720b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's generate an example, display the image that the model will take as input, and print the categories of the two overlapping components.\n",
        "\n",
        "You can re-run the cell to display new examples."
      ],
      "metadata": {
        "id": "W1DrJVzI3ysV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(datagen)\n",
        "\n",
        "print(\"first: {}, second = {}\".format(classes[np.argmax(y[0][0])],classes[np.argmax(y[1][0])+5]))\n",
        "#print(np.min(x[0]),np.max(x[0]))\n",
        "plt.imshow(x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "qL1sMtjG8VmG",
        "outputId": "c77cc6db-4ab8-42a3-a688-ff86d340d73c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first: airplane, second = truck\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79382beb61a0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "l5lzBotwL5QN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us define first of all the test generator."
      ],
      "metadata": {
        "id": "9_p4UuG1QF8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,10000)\n",
        "\n",
        "eval_samples_x, eval_samples_y = next(testgen)\n",
        "print(eval_samples_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQo8_6w-L4WY",
        "outputId": "75eb8bf2-dad9-4f09-e702-7ca65b217d29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now test a model producing random guesses. You will need to replace it with your own predictive model."
      ],
      "metadata": {
        "id": "4MiLnkKROGCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_model(x):\n",
        "  #the random model ingnore the input x and return a pair of random classes\n",
        "  return(np.random.randint(0,5,(10000,2)))"
      ],
      "metadata": {
        "id": "1GllTEtPN_xv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model):\n",
        "  eval_samples_x, eval_samples_y = next(testgen)\n",
        "  random_guesses = model(eval_samples_x)\n",
        "  correct_guesses_1 = random_guesses[:,0] == np.argmax(eval_samples_y[0],axis=1)\n",
        "  correct_guesses_2 = random_guesses[:,1] == np.argmax(eval_samples_y[1],axis=1)\n",
        "  return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2))/2"
      ],
      "metadata": {
        "id": "gomFTuuDOy8A"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_model(random_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4AL2M6yjJno",
        "outputId": "26da24fb-d283-425e-f3d7-313c548954ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1998"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the accuracy is around 1/5 = 0.2\n",
        "\n",
        "Let us repeat the evaluation ten times, and compute the standard deviation"
      ],
      "metadata": {
        "id": "7usBI88dje70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repeat_eval = 10\n",
        "eval_results = []\n",
        "for i in range(repeat_eval):\n",
        "  eval_results.append(eval_model(random_model))\n",
        "print(\"mean accuracy = \", np.mean(eval_results))\n",
        "print(\"standard deviation = \", np.std(eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFu8iEt9jdZA",
        "outputId": "482b879e-a31e-4728-99d3-9dc04691c6de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean accuracy =  0.19939999999999997\n",
            "standard deviation =  0.0013009611831257704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experiment 1:** CNN"
      ],
      "metadata": {
        "id": "BSwXyORo-aeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Define data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.Resizing(224, 224),\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(1.0),\n",
        "    layers.RandomZoom(1.0),\n",
        "    layers.RandomContrast(0.5)\n",
        "])\n",
        "\"\"\"\n",
        "# Resize CIFAR-10 images to match DenseNet121 input size\n",
        "resize_layer = layers.Lambda(lambda x: tf.image.resize(x, (32, 32)))"
      ],
      "metadata": {
        "id": "XgfvddPj-eyD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def enhanced_cnn_model():\n",
        "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
        "    #x = data_augmentation(inputs)  # Apply augmentation\n",
        "    x = resize_layer(inputs)\n",
        "\n",
        "    # First convolutional block\n",
        "    #x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "    #x = layers.MaxPooling2D((2, 2))(x)\n",
        "    shortcut = x\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(inputs)  # No activation here\n",
        "    #x = layers.LeakyReLU(alpha=0.1)(x)  # Apply LeakyReLU activation\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Adjust shortcut dimensions if necessary\n",
        "    shortcut = layers.Conv2D(128, (1, 1), padding='same')(shortcut)\n",
        "    shortcut = layers.MaxPooling2D((2, 2))(shortcut)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "\n",
        "    #x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    #x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "     # Adjust shortcut dimensions if necessary\n",
        "    shortcut = layers.Conv2D(256, (1, 1), padding='same')(shortcut)\n",
        "    shortcut = layers.MaxPooling2D((2, 2))(shortcut)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "\n",
        "    # Additional convolutional block\n",
        "    #x = layers.Conv2D(384, (3, 3), padding='same')(x)\n",
        "    #x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "    #x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    # Second convolutional block\n",
        "    #x = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    #x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "     # Adjust shortcut dimensions if necessary\n",
        "    shortcut = layers.Conv2D(512, (1, 1), padding='same')(shortcut)\n",
        "    shortcut = layers.MaxPooling2D((2, 2))(shortcut)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "\n",
        "    #x = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.Conv2D(1024, (3, 3), padding='same')(x)\n",
        "    #x = layers.LeakyReLU(alpha=0.1)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    #x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "\n",
        "    # Fully connected layers for output 1\n",
        "    #fc1_output1 = layers.Dense(1024, activation='relu')(x)\n",
        "    #fc1_output1 = layers.Dropout(0.5)(fc1_output1)\n",
        "    #output1 = layers.Dense(5, activation='softmax', name='output1')(fc1_output1)\n",
        "\n",
        "    # Fully connected layers for output 2\n",
        "    #fc1_output2 = layers.Dense(1024, activation='relu')(x)\n",
        "    #fc1_output2 = layers.Dropout(0.5)(fc1_output2)\n",
        "   #output2 = layers.Dense(5, activation='softmax', name='output2')(fc1_output2)\n",
        "\n",
        "    # Fully connected layers for output 1 with Leaky ReLU\n",
        "    fc1_output1 = layers.Dense(1024, activation=None)(x)\n",
        "    fc1_output1 = layers.LeakyReLU(alpha=0.1)(fc1_output1)\n",
        "    fc1_output1 = layers.Dropout(0.2)(fc1_output1)\n",
        "    output1 = layers.Dense(5, activation='softmax', name='output1')(fc1_output1)\n",
        "\n",
        "    # Fully connected layers for output 2 with Leaky ReLU\n",
        "    fc1_output2 = layers.Dense(1024, activation=None)(x)\n",
        "    fc1_output2 = layers.LeakyReLU(alpha=0.1)(fc1_output2)\n",
        "    fc1_output2 = layers.Dropout(0.2)(fc1_output2)\n",
        "    output2 = layers.Dense(5, activation='softmax', name='output2')(fc1_output2)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=[output1, output2])\n",
        "    return model\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "D9iEE0k8-hSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "ea0b4f52-2ac0-49d8-ea52-95fcdf78a5f3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef enhanced_cnn_model():\\n    inputs = tf.keras.Input(shape=(32, 32, 3))\\n    #x = data_augmentation(inputs)  # Apply augmentation\\n    x = resize_layer(inputs)\\n\\n    # First convolutional block\\n    #x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(inputs)\\n    #x = layers.BatchNormalization()(x)\\n    #x = layers.MaxPooling2D((2, 2))(x)\\n    shortcut = x\\n    x = layers.Conv2D(128, (3, 3), padding='same')(inputs)  # No activation here\\n    #x = layers.LeakyReLU(alpha=0.1)(x)  # Apply LeakyReLU activation\\n    x = layers.BatchNormalization()(x)\\n    x = tf.keras.activations.swish(x)\\n    #x = layers.BatchNormalization()(x)\\n    x = layers.MaxPooling2D((2, 2))(x)\\n    \\n    # Adjust shortcut dimensions if necessary\\n    shortcut = layers.Conv2D(128, (1, 1), padding='same')(shortcut)\\n    shortcut = layers.MaxPooling2D((2, 2))(shortcut)\\n    x = layers.Add()([x, shortcut])\\n\\n    #x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\\n    x = layers.Conv2D(256, (3, 3), padding='same')(x)\\n    #x = layers.LeakyReLU(alpha=0.1)(x)\\n    x = layers.BatchNormalization()(x)\\n    x = tf.keras.activations.swish(x)\\n    #x = layers.BatchNormalization()(x)\\n    x = layers.MaxPooling2D((2, 2))(x)\\n    \\n     # Adjust shortcut dimensions if necessary\\n    shortcut = layers.Conv2D(256, (1, 1), padding='same')(shortcut)\\n    shortcut = layers.MaxPooling2D((2, 2))(shortcut)\\n    x = layers.Add()([x, shortcut])\\n\\n    # Additional convolutional block\\n    #x = layers.Conv2D(384, (3, 3), padding='same')(x)\\n    #x = layers.LeakyReLU(alpha=0.1)(x)\\n    #x = layers.BatchNormalization()(x)\\n    #x = layers.MaxPooling2D((2, 2))(x)\\n\\n    # Second convolutional block\\n    #x = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)\\n    x = layers.Conv2D(512, (3, 3), padding='same')(x)\\n    #x = layers.LeakyReLU(alpha=0.1)(x)\\n    x = layers.BatchNormalization()(x)\\n    x = tf.keras.activations.swish(x)\\n    #x = layers.BatchNormalization()(x)\\n    x = layers.MaxPooling2D((2, 2))(x)\\n    \\n     # Adjust shortcut dimensions if necessary\\n    shortcut = layers.Conv2D(512, (1, 1), padding='same')(shortcut)\\n    shortcut = layers.MaxPooling2D((2, 2))(shortcut)\\n    x = layers.Add()([x, shortcut])\\n\\n    #x = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(x)\\n    x = layers.Conv2D(1024, (3, 3), padding='same')(x)\\n    #x = layers.LeakyReLU(alpha=0.1)(x)\\n    x = layers.BatchNormalization()(x)\\n    x = tf.keras.activations.swish(x)\\n    #x = layers.BatchNormalization()(x)\\n    x = layers.MaxPooling2D((2, 2))(x)\\n    x = layers.Add()([x, shortcut])\\n\\n    # Global Average Pooling\\n    x = layers.GlobalAveragePooling2D()(x)\\n\\n    \\n    # Fully connected layers for output 1\\n    #fc1_output1 = layers.Dense(1024, activation='relu')(x)\\n    #fc1_output1 = layers.Dropout(0.5)(fc1_output1)\\n    #output1 = layers.Dense(5, activation='softmax', name='output1')(fc1_output1)\\n\\n    # Fully connected layers for output 2\\n    #fc1_output2 = layers.Dense(1024, activation='relu')(x)\\n    #fc1_output2 = layers.Dropout(0.5)(fc1_output2)\\n   #output2 = layers.Dense(5, activation='softmax', name='output2')(fc1_output2)\\n    \\n    # Fully connected layers for output 1 with Leaky ReLU\\n    fc1_output1 = layers.Dense(1024, activation=None)(x)\\n    fc1_output1 = layers.LeakyReLU(alpha=0.1)(fc1_output1)\\n    fc1_output1 = layers.Dropout(0.2)(fc1_output1)\\n    output1 = layers.Dense(5, activation='softmax', name='output1')(fc1_output1)\\n\\n    # Fully connected layers for output 2 with Leaky ReLU\\n    fc1_output2 = layers.Dense(1024, activation=None)(x)\\n    fc1_output2 = layers.LeakyReLU(alpha=0.1)(fc1_output2)\\n    fc1_output2 = layers.Dropout(0.2)(fc1_output2)\\n    output2 = layers.Dense(5, activation='softmax', name='output2')(fc1_output2)\\n\\n    model = Model(inputs=inputs, outputs=[output1, output2])\\n    return model\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enhanced_cnn_model():\n",
        "    inputs = tf.keras.Input(shape=(32, 32, 3))\n",
        "    x = resize_layer(inputs)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    x = layers.MaxPooling2D((1, 1))(x)\n",
        "\n",
        "    # First convolutional block\n",
        "    #shortcut = x\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    x = layers.MaxPooling2D((1, 1))(x)\n",
        "\n",
        "    # Downsample shortcut to match x\n",
        "    #shortcut = layers.Conv2D(128, (1, 1), strides=(2, 2), padding='same')(shortcut)\n",
        "    #x = layers.Add()([x, shortcut])\n",
        "\n",
        "    # Second convolutional block\n",
        "    #shortcut = x\n",
        "    x = layers.Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    x = layers.MaxPooling2D((1, 1))(x)\n",
        "\n",
        "    # Downsample shortcut to match x\n",
        "    #shortcut = layers.Conv2D(256, (1, 1), strides=(2, 2), padding='same')(shortcut)\n",
        "    #x = layers.Add()([x, shortcut])\n",
        "\n",
        "    # Third convolutional block\n",
        "    #shortcut = x\n",
        "    x = layers.Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    x = layers.MaxPooling2D((1, 1))(x)\n",
        "\n",
        "    # Downsample shortcut to match x\n",
        "    #shortcut = layers.Conv2D(512, (1, 1), strides=(2, 2), padding='same')(shortcut)\n",
        "    #x = layers.Add()([x, shortcut])\n",
        "\n",
        "    # Fourth convolutional block\n",
        "    #shortcut = x\n",
        "    x = layers.Conv2D(1024, (3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = tf.keras.activations.swish(x)\n",
        "    x = layers.MaxPooling2D((1, 1))(x)\n",
        "\n",
        "    # Downsample shortcut to match x\n",
        "    #shortcut = layers.Conv2D(1024, (1, 1), strides=(2, 2), padding='same')(shortcut)\n",
        "    #x = layers.Add()([x, shortcut])\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Fully connected layers for output 1\n",
        "    fc1_output1 = layers.Dense(1024, activation=None)(x)\n",
        "    fc1_output1 = layers.LeakyReLU(alpha=0.1)(fc1_output1)\n",
        "    fc1_output1 = layers.Dropout(0.2)(fc1_output1)\n",
        "    output1 = layers.Dense(5, activation='softmax', name='output1')(fc1_output1)\n",
        "\n",
        "    # Fully connected layers for output 2\n",
        "    fc1_output2 = layers.Dense(1024, activation=None)(x)\n",
        "    fc1_output2 = layers.LeakyReLU(alpha=0.1)(fc1_output2)\n",
        "    fc1_output2 = layers.Dropout(0.2)(fc1_output2)\n",
        "    output2 = layers.Dense(5, activation='softmax', name='output2')(fc1_output2)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=[output1, output2])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "-IlYR9Zw8TYw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LabelSmoothingLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, smoothing=0.0):\n",
        "        super(LabelSmoothingLoss, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        num_classes = tf.cast(tf.shape(y_pred)[-1], tf.float32)\n",
        "        smooth_positives = 1.0 - self.smoothing\n",
        "        smooth_negatives = self.smoothing / num_classes\n",
        "        y_true_smoothed = y_true * smooth_positives + smooth_negatives\n",
        "        return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_true_smoothed, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "id": "hF4VzmWr-jwZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define learning rate scheduler\n",
        "initial_lr = 0.001\n",
        "scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=initial_lr,\n",
        "    decay_steps= 5 * 500,  # Assuming 10 epochs\n",
        "    decay_rate=0.8,\n",
        "    staircase=True\n",
        ")"
      ],
      "metadata": {
        "id": "Q7Bb5-n--l9y"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer with layer-specific learning rates\n",
        "class CustomAdam(tf.keras.optimizers.Adam):\n",
        "    def __init__(self, lr_multipliers, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.lr_multipliers = lr_multipliers\n",
        "\n",
        "    def _resource_apply_dense(self, grad, var, apply_state=None):\n",
        "        multiplier = self.lr_multipliers.get(var.name, 1.0)\n",
        "        scaled_lr = self._get_hyper(\"learning_rate\") * multiplier\n",
        "        self._set_hyper(\"learning_rate\", scaled_lr)\n",
        "        return super()._resource_apply_dense(grad, var, apply_state)\n",
        "\"\"\"\n",
        "# Define learning rate multipliers\n",
        "lr_multipliers = {\n",
        "    'conv2d/kernel:0': 1e-5,  # Early layers\n",
        "    'conv2d_1/kernel:0': 1e-5,\n",
        "    'conv2d_2/kernel:0': 1e-3,  # Middle layers\n",
        "    'conv2d_3/kernel:0': 1e-3,\n",
        "    'dense/kernel:0': 1e-3,  # Final dense layers\n",
        "    'dense_1/kernel:0': 1e-3\n",
        "}\n",
        "\"\"\"\n",
        "lr_multipliers = {\n",
        "    'conv2d/kernel:0': 1e-5,    # Early layers\n",
        "    'conv2d_1/kernel:0': 1e-5,  # Early layers\n",
        "    'conv2d_2/kernel:0': 1e-4,  # Middle layers\n",
        "    'conv2d_3/kernel:0': 1e-4,  # Middle layers\n",
        "    'conv2d_4/kernel:0': 1e-3,  # Late layers\n",
        "    'conv2d_5/kernel:0': 1e-3,  # Late layers\n",
        "    'dense/kernel:0': 1e-3,     # Final dense layers\n",
        "    'dense_1/kernel:0': 1e-3\n",
        "}\n",
        "\n",
        "# Compile the model with a custom optimizer\n",
        "custom_optimizer = CustomAdam(\n",
        "    learning_rate=scheduler,\n",
        "    lr_multipliers=lr_multipliers\n",
        ")"
      ],
      "metadata": {
        "id": "fGAUI5og-n3s"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = enhanced_cnn_model()\n",
        "model.compile(\n",
        "    optimizer=custom_optimizer,\n",
        "    loss={'output1': LabelSmoothingLoss(smoothing=0.1), 'output2': LabelSmoothingLoss(smoothing=0.1)},\n",
        "    metrics={'output1': 'accuracy', 'output2': 'accuracy'}\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=scheduler),\n",
        "    loss={'output1': LabelSmoothingLoss(smoothing=0.1), 'output2': LabelSmoothingLoss(smoothing=0.1)},\n",
        "    metrics={'output1': 'accuracy', 'output2': 'accuracy'}\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=scheduler),\n",
        "              loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
        "              metrics={'output1': 'accuracy', 'output2': 'accuracy'})\n",
        "\"\"\"\n",
        "\n",
        "train_gen = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, 64)\n",
        "val_gen = datagenerator(cifar10_x_val_1, cifar10_x_val_2, cifar10_y_val_1, cifar10_y_val_2, 64)\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=500,\n",
        "    epochs=110,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=100\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pi_ru1r-qqn",
        "outputId": "b2473d18-67c1-4858-bb5b-c33ed293c710"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 36ms/step - loss: 2.9897 - output1_accuracy: 0.3653 - output1_loss: 1.5063 - output2_accuracy: 0.3901 - output2_loss: 1.4833 - val_loss: 3.1424 - val_output1_accuracy: 0.3467 - val_output1_loss: 1.5883 - val_output2_accuracy: 0.4300 - val_output2_loss: 1.5541\n",
            "Epoch 2/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.6528 - output1_accuracy: 0.4450 - output1_loss: 1.3803 - output2_accuracy: 0.5261 - output2_loss: 1.2725 - val_loss: 2.6278 - val_output1_accuracy: 0.4347 - val_output1_loss: 1.4114 - val_output2_accuracy: 0.5561 - val_output2_loss: 1.2164\n",
            "Epoch 3/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.5047 - output1_accuracy: 0.4782 - output1_loss: 1.3313 - output2_accuracy: 0.5862 - output2_loss: 1.1734 - val_loss: 2.8630 - val_output1_accuracy: 0.4022 - val_output1_loss: 1.5289 - val_output2_accuracy: 0.5198 - val_output2_loss: 1.3342\n",
            "Epoch 4/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.4190 - output1_accuracy: 0.4999 - output1_loss: 1.3011 - output2_accuracy: 0.6200 - output2_loss: 1.1180 - val_loss: 2.7145 - val_output1_accuracy: 0.3269 - val_output1_loss: 1.6072 - val_output2_accuracy: 0.6269 - val_output2_loss: 1.1074\n",
            "Epoch 5/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.3466 - output1_accuracy: 0.5230 - output1_loss: 1.2626 - output2_accuracy: 0.6423 - output2_loss: 1.0841 - val_loss: 2.7046 - val_output1_accuracy: 0.4034 - val_output1_loss: 1.5642 - val_output2_accuracy: 0.5980 - val_output2_loss: 1.1404\n",
            "Epoch 6/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.2818 - output1_accuracy: 0.5397 - output1_loss: 1.2376 - output2_accuracy: 0.6662 - output2_loss: 1.0442 - val_loss: 2.7681 - val_output1_accuracy: 0.4233 - val_output1_loss: 1.5219 - val_output2_accuracy: 0.5567 - val_output2_loss: 1.2462\n",
            "Epoch 7/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.2198 - output1_accuracy: 0.5608 - output1_loss: 1.2078 - output2_accuracy: 0.6817 - output2_loss: 1.0120 - val_loss: 2.4220 - val_output1_accuracy: 0.4944 - val_output1_loss: 1.3408 - val_output2_accuracy: 0.6528 - val_output2_loss: 1.0812\n",
            "Epoch 8/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.1889 - output1_accuracy: 0.5731 - output1_loss: 1.1856 - output2_accuracy: 0.6901 - output2_loss: 1.0033 - val_loss: 2.5018 - val_output1_accuracy: 0.5167 - val_output1_loss: 1.3017 - val_output2_accuracy: 0.5972 - val_output2_loss: 1.2001\n",
            "Epoch 9/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.1426 - output1_accuracy: 0.5828 - output1_loss: 1.1695 - output2_accuracy: 0.7064 - output2_loss: 0.9731 - val_loss: 2.1726 - val_output1_accuracy: 0.5833 - val_output1_loss: 1.1747 - val_output2_accuracy: 0.6930 - val_output2_loss: 0.9979\n",
            "Epoch 10/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.1085 - output1_accuracy: 0.5953 - output1_loss: 1.1503 - output2_accuracy: 0.7119 - output2_loss: 0.9582 - val_loss: 2.7252 - val_output1_accuracy: 0.3967 - val_output1_loss: 1.6402 - val_output2_accuracy: 0.6381 - val_output2_loss: 1.0850\n",
            "Epoch 11/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.0706 - output1_accuracy: 0.6099 - output1_loss: 1.1360 - output2_accuracy: 0.7285 - output2_loss: 0.9346 - val_loss: 2.3025 - val_output1_accuracy: 0.5170 - val_output1_loss: 1.3295 - val_output2_accuracy: 0.7042 - val_output2_loss: 0.9730\n",
            "Epoch 12/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.0394 - output1_accuracy: 0.6160 - output1_loss: 1.1149 - output2_accuracy: 0.7317 - output2_loss: 0.9245 - val_loss: 2.4207 - val_output1_accuracy: 0.5023 - val_output1_loss: 1.2976 - val_output2_accuracy: 0.6394 - val_output2_loss: 1.1230\n",
            "Epoch 13/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 2.0139 - output1_accuracy: 0.6297 - output1_loss: 1.0953 - output2_accuracy: 0.7357 - output2_loss: 0.9186 - val_loss: 2.4635 - val_output1_accuracy: 0.5070 - val_output1_loss: 1.3834 - val_output2_accuracy: 0.6464 - val_output2_loss: 1.0801\n",
            "Epoch 14/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.9926 - output1_accuracy: 0.6290 - output1_loss: 1.0936 - output2_accuracy: 0.7466 - output2_loss: 0.8990 - val_loss: 2.1433 - val_output1_accuracy: 0.5908 - val_output1_loss: 1.1743 - val_output2_accuracy: 0.7056 - val_output2_loss: 0.9691\n",
            "Epoch 15/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.9846 - output1_accuracy: 0.6338 - output1_loss: 1.0873 - output2_accuracy: 0.7474 - output2_loss: 0.8973 - val_loss: 2.2304 - val_output1_accuracy: 0.5305 - val_output1_loss: 1.2993 - val_output2_accuracy: 0.7300 - val_output2_loss: 0.9311\n",
            "Epoch 16/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.9353 - output1_accuracy: 0.6536 - output1_loss: 1.0607 - output2_accuracy: 0.7613 - output2_loss: 0.8746 - val_loss: 2.0659 - val_output1_accuracy: 0.6156 - val_output1_loss: 1.1107 - val_output2_accuracy: 0.7186 - val_output2_loss: 0.9552\n",
            "Epoch 17/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.9092 - output1_accuracy: 0.6607 - output1_loss: 1.0442 - output2_accuracy: 0.7681 - output2_loss: 0.8649 - val_loss: 2.1558 - val_output1_accuracy: 0.5495 - val_output1_loss: 1.2507 - val_output2_accuracy: 0.7408 - val_output2_loss: 0.9051\n",
            "Epoch 18/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.8914 - output1_accuracy: 0.6616 - output1_loss: 1.0374 - output2_accuracy: 0.7699 - output2_loss: 0.8540 - val_loss: 2.0663 - val_output1_accuracy: 0.6103 - val_output1_loss: 1.1363 - val_output2_accuracy: 0.7320 - val_output2_loss: 0.9300\n",
            "Epoch 19/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.8924 - output1_accuracy: 0.6642 - output1_loss: 1.0432 - output2_accuracy: 0.7740 - output2_loss: 0.8492 - val_loss: 1.9764 - val_output1_accuracy: 0.6198 - val_output1_loss: 1.0922 - val_output2_accuracy: 0.7487 - val_output2_loss: 0.8842\n",
            "Epoch 20/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.8684 - output1_accuracy: 0.6761 - output1_loss: 1.0184 - output2_accuracy: 0.7743 - output2_loss: 0.8500 - val_loss: 2.0167 - val_output1_accuracy: 0.6200 - val_output1_loss: 1.1214 - val_output2_accuracy: 0.7455 - val_output2_loss: 0.8953\n",
            "Epoch 21/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.8461 - output1_accuracy: 0.6780 - output1_loss: 1.0086 - output2_accuracy: 0.7794 - output2_loss: 0.8375 - val_loss: 2.0052 - val_output1_accuracy: 0.6264 - val_output1_loss: 1.0923 - val_output2_accuracy: 0.7337 - val_output2_loss: 0.9130\n",
            "Epoch 22/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.8153 - output1_accuracy: 0.6924 - output1_loss: 0.9885 - output2_accuracy: 0.7856 - output2_loss: 0.8268 - val_loss: 2.0047 - val_output1_accuracy: 0.6394 - val_output1_loss: 1.0738 - val_output2_accuracy: 0.7267 - val_output2_loss: 0.9309\n",
            "Epoch 23/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.8119 - output1_accuracy: 0.6919 - output1_loss: 0.9924 - output2_accuracy: 0.7882 - output2_loss: 0.8195 - val_loss: 2.1177 - val_output1_accuracy: 0.6059 - val_output1_loss: 1.1595 - val_output2_accuracy: 0.7195 - val_output2_loss: 0.9582\n",
            "Epoch 24/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.7985 - output1_accuracy: 0.6942 - output1_loss: 0.9855 - output2_accuracy: 0.7923 - output2_loss: 0.8129 - val_loss: 1.8308 - val_output1_accuracy: 0.6814 - val_output1_loss: 1.0020 - val_output2_accuracy: 0.7841 - val_output2_loss: 0.8288\n",
            "Epoch 25/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.7699 - output1_accuracy: 0.7022 - output1_loss: 0.9683 - output2_accuracy: 0.7980 - output2_loss: 0.8016 - val_loss: 1.9089 - val_output1_accuracy: 0.6536 - val_output1_loss: 1.0541 - val_output2_accuracy: 0.7694 - val_output2_loss: 0.8549\n",
            "Epoch 26/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.7448 - output1_accuracy: 0.7091 - output1_loss: 0.9543 - output2_accuracy: 0.8024 - output2_loss: 0.7905 - val_loss: 1.9637 - val_output1_accuracy: 0.6319 - val_output1_loss: 1.0897 - val_output2_accuracy: 0.7514 - val_output2_loss: 0.8740\n",
            "Epoch 27/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.7316 - output1_accuracy: 0.7127 - output1_loss: 0.9465 - output2_accuracy: 0.8109 - output2_loss: 0.7851 - val_loss: 1.8377 - val_output1_accuracy: 0.6736 - val_output1_loss: 1.0259 - val_output2_accuracy: 0.7931 - val_output2_loss: 0.8118\n",
            "Epoch 28/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.7298 - output1_accuracy: 0.7163 - output1_loss: 0.9488 - output2_accuracy: 0.8103 - output2_loss: 0.7810 - val_loss: 1.9330 - val_output1_accuracy: 0.6442 - val_output1_loss: 1.0658 - val_output2_accuracy: 0.7608 - val_output2_loss: 0.8672\n",
            "Epoch 29/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.7334 - output1_accuracy: 0.7093 - output1_loss: 0.9542 - output2_accuracy: 0.8092 - output2_loss: 0.7792 - val_loss: 1.8533 - val_output1_accuracy: 0.6742 - val_output1_loss: 1.0088 - val_output2_accuracy: 0.7763 - val_output2_loss: 0.8445\n",
            "Epoch 30/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.7118 - output1_accuracy: 0.7224 - output1_loss: 0.9381 - output2_accuracy: 0.8130 - output2_loss: 0.7737 - val_loss: 1.9314 - val_output1_accuracy: 0.6459 - val_output1_loss: 1.0620 - val_output2_accuracy: 0.7616 - val_output2_loss: 0.8694\n",
            "Epoch 31/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.7070 - output1_accuracy: 0.7189 - output1_loss: 0.9397 - output2_accuracy: 0.8173 - output2_loss: 0.7673 - val_loss: 1.7698 - val_output1_accuracy: 0.6933 - val_output1_loss: 0.9743 - val_output2_accuracy: 0.7992 - val_output2_loss: 0.7954\n",
            "Epoch 32/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6925 - output1_accuracy: 0.7289 - output1_loss: 0.9220 - output2_accuracy: 0.8149 - output2_loss: 0.7705 - val_loss: 1.7888 - val_output1_accuracy: 0.7023 - val_output1_loss: 0.9687 - val_output2_accuracy: 0.7914 - val_output2_loss: 0.8201\n",
            "Epoch 33/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6850 - output1_accuracy: 0.7278 - output1_loss: 0.9256 - output2_accuracy: 0.8226 - output2_loss: 0.7594 - val_loss: 1.7472 - val_output1_accuracy: 0.7061 - val_output1_loss: 0.9612 - val_output2_accuracy: 0.8041 - val_output2_loss: 0.7861\n",
            "Epoch 34/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6773 - output1_accuracy: 0.7296 - output1_loss: 0.9222 - output2_accuracy: 0.8246 - output2_loss: 0.7551 - val_loss: 1.8134 - val_output1_accuracy: 0.6834 - val_output1_loss: 0.9951 - val_output2_accuracy: 0.7886 - val_output2_loss: 0.8182\n",
            "Epoch 35/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6635 - output1_accuracy: 0.7334 - output1_loss: 0.9126 - output2_accuracy: 0.8258 - output2_loss: 0.7509 - val_loss: 1.7531 - val_output1_accuracy: 0.7013 - val_output1_loss: 0.9617 - val_output2_accuracy: 0.7983 - val_output2_loss: 0.7915\n",
            "Epoch 36/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6635 - output1_accuracy: 0.7403 - output1_loss: 0.9126 - output2_accuracy: 0.8249 - output2_loss: 0.7509 - val_loss: 1.7788 - val_output1_accuracy: 0.7072 - val_output1_loss: 0.9661 - val_output2_accuracy: 0.7837 - val_output2_loss: 0.8126\n",
            "Epoch 37/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6405 - output1_accuracy: 0.7472 - output1_loss: 0.8952 - output2_accuracy: 0.8313 - output2_loss: 0.7453 - val_loss: 1.7108 - val_output1_accuracy: 0.7186 - val_output1_loss: 0.9343 - val_output2_accuracy: 0.8067 - val_output2_loss: 0.7765\n",
            "Epoch 38/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6465 - output1_accuracy: 0.7428 - output1_loss: 0.9014 - output2_accuracy: 0.8290 - output2_loss: 0.7451 - val_loss: 1.7501 - val_output1_accuracy: 0.7075 - val_output1_loss: 0.9600 - val_output2_accuracy: 0.8020 - val_output2_loss: 0.7901\n",
            "Epoch 39/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6309 - output1_accuracy: 0.7474 - output1_loss: 0.8922 - output2_accuracy: 0.8337 - output2_loss: 0.7387 - val_loss: 1.7051 - val_output1_accuracy: 0.7306 - val_output1_loss: 0.9282 - val_output2_accuracy: 0.8103 - val_output2_loss: 0.7769\n",
            "Epoch 40/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.6277 - output1_accuracy: 0.7445 - output1_loss: 0.8962 - output2_accuracy: 0.8374 - output2_loss: 0.7315 - val_loss: 1.7514 - val_output1_accuracy: 0.6889 - val_output1_loss: 0.9826 - val_output2_accuracy: 0.8139 - val_output2_loss: 0.7688\n",
            "Epoch 41/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6099 - output1_accuracy: 0.7513 - output1_loss: 0.8826 - output2_accuracy: 0.8372 - output2_loss: 0.7273 - val_loss: 1.6959 - val_output1_accuracy: 0.7098 - val_output1_loss: 0.9448 - val_output2_accuracy: 0.8209 - val_output2_loss: 0.7510\n",
            "Epoch 42/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.6067 - output1_accuracy: 0.7567 - output1_loss: 0.8834 - output2_accuracy: 0.8417 - output2_loss: 0.7233 - val_loss: 1.6862 - val_output1_accuracy: 0.7212 - val_output1_loss: 0.9237 - val_output2_accuracy: 0.8175 - val_output2_loss: 0.7625\n",
            "Epoch 43/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.6080 - output1_accuracy: 0.7557 - output1_loss: 0.8773 - output2_accuracy: 0.8370 - output2_loss: 0.7307 - val_loss: 1.7594 - val_output1_accuracy: 0.7027 - val_output1_loss: 0.9679 - val_output2_accuracy: 0.8031 - val_output2_loss: 0.7915\n",
            "Epoch 44/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5949 - output1_accuracy: 0.7613 - output1_loss: 0.8726 - output2_accuracy: 0.8420 - output2_loss: 0.7223 - val_loss: 1.7147 - val_output1_accuracy: 0.7161 - val_output1_loss: 0.9308 - val_output2_accuracy: 0.8078 - val_output2_loss: 0.7839\n",
            "Epoch 45/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5916 - output1_accuracy: 0.7608 - output1_loss: 0.8690 - output2_accuracy: 0.8418 - output2_loss: 0.7226 - val_loss: 1.7063 - val_output1_accuracy: 0.7197 - val_output1_loss: 0.9456 - val_output2_accuracy: 0.8141 - val_output2_loss: 0.7607\n",
            "Epoch 46/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5874 - output1_accuracy: 0.7607 - output1_loss: 0.8686 - output2_accuracy: 0.8465 - output2_loss: 0.7188 - val_loss: 1.6770 - val_output1_accuracy: 0.7248 - val_output1_loss: 0.9215 - val_output2_accuracy: 0.8206 - val_output2_loss: 0.7555\n",
            "Epoch 47/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5840 - output1_accuracy: 0.7628 - output1_loss: 0.8651 - output2_accuracy: 0.8429 - output2_loss: 0.7189 - val_loss: 1.7118 - val_output1_accuracy: 0.7153 - val_output1_loss: 0.9467 - val_output2_accuracy: 0.8108 - val_output2_loss: 0.7651\n",
            "Epoch 48/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5744 - output1_accuracy: 0.7621 - output1_loss: 0.8655 - output2_accuracy: 0.8505 - output2_loss: 0.7089 - val_loss: 1.6845 - val_output1_accuracy: 0.7248 - val_output1_loss: 0.9284 - val_output2_accuracy: 0.8203 - val_output2_loss: 0.7561\n",
            "Epoch 49/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5718 - output1_accuracy: 0.7648 - output1_loss: 0.8625 - output2_accuracy: 0.8493 - output2_loss: 0.7093 - val_loss: 1.6629 - val_output1_accuracy: 0.7352 - val_output1_loss: 0.9105 - val_output2_accuracy: 0.8223 - val_output2_loss: 0.7524\n",
            "Epoch 50/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5728 - output1_accuracy: 0.7635 - output1_loss: 0.8610 - output2_accuracy: 0.8441 - output2_loss: 0.7118 - val_loss: 1.6899 - val_output1_accuracy: 0.7305 - val_output1_loss: 0.9196 - val_output2_accuracy: 0.8138 - val_output2_loss: 0.7704\n",
            "Epoch 51/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5523 - output1_accuracy: 0.7713 - output1_loss: 0.8513 - output2_accuracy: 0.8536 - output2_loss: 0.7010 - val_loss: 1.6595 - val_output1_accuracy: 0.7280 - val_output1_loss: 0.9174 - val_output2_accuracy: 0.8272 - val_output2_loss: 0.7421\n",
            "Epoch 52/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5533 - output1_accuracy: 0.7791 - output1_loss: 0.8451 - output2_accuracy: 0.8467 - output2_loss: 0.7082 - val_loss: 1.6523 - val_output1_accuracy: 0.7434 - val_output1_loss: 0.8945 - val_output2_accuracy: 0.8166 - val_output2_loss: 0.7577\n",
            "Epoch 53/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5494 - output1_accuracy: 0.7737 - output1_loss: 0.8453 - output2_accuracy: 0.8516 - output2_loss: 0.7041 - val_loss: 1.6491 - val_output1_accuracy: 0.7303 - val_output1_loss: 0.9150 - val_output2_accuracy: 0.8341 - val_output2_loss: 0.7342\n",
            "Epoch 54/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.5531 - output1_accuracy: 0.7700 - output1_loss: 0.8521 - output2_accuracy: 0.8524 - output2_loss: 0.7010 - val_loss: 1.6579 - val_output1_accuracy: 0.7305 - val_output1_loss: 0.9157 - val_output2_accuracy: 0.8298 - val_output2_loss: 0.7422\n",
            "Epoch 55/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.5425 - output1_accuracy: 0.7775 - output1_loss: 0.8414 - output2_accuracy: 0.8540 - output2_loss: 0.7011 - val_loss: 1.6306 - val_output1_accuracy: 0.7422 - val_output1_loss: 0.8994 - val_output2_accuracy: 0.8375 - val_output2_loss: 0.7313\n",
            "Epoch 56/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5406 - output1_accuracy: 0.7734 - output1_loss: 0.8411 - output2_accuracy: 0.8522 - output2_loss: 0.6995 - val_loss: 1.6229 - val_output1_accuracy: 0.7427 - val_output1_loss: 0.8977 - val_output2_accuracy: 0.8352 - val_output2_loss: 0.7252\n",
            "Epoch 57/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.5301 - output1_accuracy: 0.7756 - output1_loss: 0.8386 - output2_accuracy: 0.8552 - output2_loss: 0.6915 - val_loss: 1.6486 - val_output1_accuracy: 0.7297 - val_output1_loss: 0.9110 - val_output2_accuracy: 0.8395 - val_output2_loss: 0.7376\n",
            "Epoch 58/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5311 - output1_accuracy: 0.7782 - output1_loss: 0.8390 - output2_accuracy: 0.8586 - output2_loss: 0.6921 - val_loss: 1.6312 - val_output1_accuracy: 0.7477 - val_output1_loss: 0.8911 - val_output2_accuracy: 0.8270 - val_output2_loss: 0.7401\n",
            "Epoch 59/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5409 - output1_accuracy: 0.7736 - output1_loss: 0.8441 - output2_accuracy: 0.8550 - output2_loss: 0.6967 - val_loss: 1.6389 - val_output1_accuracy: 0.7437 - val_output1_loss: 0.8970 - val_output2_accuracy: 0.8256 - val_output2_loss: 0.7419\n",
            "Epoch 60/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5292 - output1_accuracy: 0.7777 - output1_loss: 0.8372 - output2_accuracy: 0.8556 - output2_loss: 0.6920 - val_loss: 1.6406 - val_output1_accuracy: 0.7345 - val_output1_loss: 0.9147 - val_output2_accuracy: 0.8392 - val_output2_loss: 0.7259\n",
            "Epoch 61/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5266 - output1_accuracy: 0.7802 - output1_loss: 0.8350 - output2_accuracy: 0.8587 - output2_loss: 0.6916 - val_loss: 1.6395 - val_output1_accuracy: 0.7319 - val_output1_loss: 0.9110 - val_output2_accuracy: 0.8353 - val_output2_loss: 0.7285\n",
            "Epoch 62/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5171 - output1_accuracy: 0.7823 - output1_loss: 0.8295 - output2_accuracy: 0.8586 - output2_loss: 0.6875 - val_loss: 1.6286 - val_output1_accuracy: 0.7386 - val_output1_loss: 0.8981 - val_output2_accuracy: 0.8378 - val_output2_loss: 0.7305\n",
            "Epoch 63/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5194 - output1_accuracy: 0.7839 - output1_loss: 0.8315 - output2_accuracy: 0.8590 - output2_loss: 0.6879 - val_loss: 1.6248 - val_output1_accuracy: 0.7419 - val_output1_loss: 0.8947 - val_output2_accuracy: 0.8336 - val_output2_loss: 0.7301\n",
            "Epoch 64/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5149 - output1_accuracy: 0.7828 - output1_loss: 0.8261 - output2_accuracy: 0.8580 - output2_loss: 0.6887 - val_loss: 1.6170 - val_output1_accuracy: 0.7414 - val_output1_loss: 0.8889 - val_output2_accuracy: 0.8395 - val_output2_loss: 0.7281\n",
            "Epoch 65/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.5140 - output1_accuracy: 0.7857 - output1_loss: 0.8285 - output2_accuracy: 0.8598 - output2_loss: 0.6855 - val_loss: 1.6562 - val_output1_accuracy: 0.7358 - val_output1_loss: 0.9048 - val_output2_accuracy: 0.8245 - val_output2_loss: 0.7514\n",
            "Epoch 66/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5137 - output1_accuracy: 0.7842 - output1_loss: 0.8252 - output2_accuracy: 0.8587 - output2_loss: 0.6885 - val_loss: 1.6386 - val_output1_accuracy: 0.7452 - val_output1_loss: 0.9000 - val_output2_accuracy: 0.8313 - val_output2_loss: 0.7385\n",
            "Epoch 67/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5084 - output1_accuracy: 0.7863 - output1_loss: 0.8259 - output2_accuracy: 0.8667 - output2_loss: 0.6825 - val_loss: 1.6115 - val_output1_accuracy: 0.7506 - val_output1_loss: 0.8878 - val_output2_accuracy: 0.8358 - val_output2_loss: 0.7237\n",
            "Epoch 68/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5057 - output1_accuracy: 0.7893 - output1_loss: 0.8191 - output2_accuracy: 0.8618 - output2_loss: 0.6866 - val_loss: 1.6144 - val_output1_accuracy: 0.7494 - val_output1_loss: 0.8904 - val_output2_accuracy: 0.8395 - val_output2_loss: 0.7240\n",
            "Epoch 69/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4994 - output1_accuracy: 0.7854 - output1_loss: 0.8207 - output2_accuracy: 0.8680 - output2_loss: 0.6787 - val_loss: 1.6086 - val_output1_accuracy: 0.7464 - val_output1_loss: 0.8866 - val_output2_accuracy: 0.8363 - val_output2_loss: 0.7220\n",
            "Epoch 70/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.5008 - output1_accuracy: 0.7892 - output1_loss: 0.8207 - output2_accuracy: 0.8648 - output2_loss: 0.6801 - val_loss: 1.6199 - val_output1_accuracy: 0.7489 - val_output1_loss: 0.8835 - val_output2_accuracy: 0.8322 - val_output2_loss: 0.7364\n",
            "Epoch 71/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4949 - output1_accuracy: 0.7931 - output1_loss: 0.8143 - output2_accuracy: 0.8640 - output2_loss: 0.6806 - val_loss: 1.6444 - val_output1_accuracy: 0.7417 - val_output1_loss: 0.8998 - val_output2_accuracy: 0.8270 - val_output2_loss: 0.7446\n",
            "Epoch 72/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4960 - output1_accuracy: 0.7894 - output1_loss: 0.8172 - output2_accuracy: 0.8646 - output2_loss: 0.6787 - val_loss: 1.6136 - val_output1_accuracy: 0.7452 - val_output1_loss: 0.8879 - val_output2_accuracy: 0.8334 - val_output2_loss: 0.7258\n",
            "Epoch 73/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4929 - output1_accuracy: 0.7914 - output1_loss: 0.8143 - output2_accuracy: 0.8645 - output2_loss: 0.6786 - val_loss: 1.6102 - val_output1_accuracy: 0.7472 - val_output1_loss: 0.8875 - val_output2_accuracy: 0.8369 - val_output2_loss: 0.7228\n",
            "Epoch 74/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4952 - output1_accuracy: 0.7945 - output1_loss: 0.8104 - output2_accuracy: 0.8610 - output2_loss: 0.6848 - val_loss: 1.6291 - val_output1_accuracy: 0.7459 - val_output1_loss: 0.8853 - val_output2_accuracy: 0.8256 - val_output2_loss: 0.7438\n",
            "Epoch 75/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4959 - output1_accuracy: 0.7895 - output1_loss: 0.8179 - output2_accuracy: 0.8671 - output2_loss: 0.6780 - val_loss: 1.6043 - val_output1_accuracy: 0.7483 - val_output1_loss: 0.8837 - val_output2_accuracy: 0.8428 - val_output2_loss: 0.7207\n",
            "Epoch 76/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4938 - output1_accuracy: 0.7947 - output1_loss: 0.8136 - output2_accuracy: 0.8622 - output2_loss: 0.6802 - val_loss: 1.6303 - val_output1_accuracy: 0.7464 - val_output1_loss: 0.8993 - val_output2_accuracy: 0.8306 - val_output2_loss: 0.7310\n",
            "Epoch 77/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4852 - output1_accuracy: 0.7971 - output1_loss: 0.8088 - output2_accuracy: 0.8655 - output2_loss: 0.6764 - val_loss: 1.6058 - val_output1_accuracy: 0.7520 - val_output1_loss: 0.8830 - val_output2_accuracy: 0.8369 - val_output2_loss: 0.7228\n",
            "Epoch 78/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4743 - output1_accuracy: 0.7948 - output1_loss: 0.8085 - output2_accuracy: 0.8728 - output2_loss: 0.6658 - val_loss: 1.6138 - val_output1_accuracy: 0.7503 - val_output1_loss: 0.8822 - val_output2_accuracy: 0.8297 - val_output2_loss: 0.7316\n",
            "Epoch 79/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4975 - output1_accuracy: 0.7884 - output1_loss: 0.8203 - output2_accuracy: 0.8681 - output2_loss: 0.6772 - val_loss: 1.5984 - val_output1_accuracy: 0.7614 - val_output1_loss: 0.8763 - val_output2_accuracy: 0.8416 - val_output2_loss: 0.7221\n",
            "Epoch 80/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4886 - output1_accuracy: 0.7930 - output1_loss: 0.8140 - output2_accuracy: 0.8679 - output2_loss: 0.6746 - val_loss: 1.6420 - val_output1_accuracy: 0.7441 - val_output1_loss: 0.9088 - val_output2_accuracy: 0.8308 - val_output2_loss: 0.7331\n",
            "Epoch 81/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4885 - output1_accuracy: 0.7898 - output1_loss: 0.8167 - output2_accuracy: 0.8696 - output2_loss: 0.6718 - val_loss: 1.6079 - val_output1_accuracy: 0.7550 - val_output1_loss: 0.8731 - val_output2_accuracy: 0.8311 - val_output2_loss: 0.7348\n",
            "Epoch 82/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4744 - output1_accuracy: 0.8010 - output1_loss: 0.8003 - output2_accuracy: 0.8668 - output2_loss: 0.6741 - val_loss: 1.6145 - val_output1_accuracy: 0.7459 - val_output1_loss: 0.8897 - val_output2_accuracy: 0.8378 - val_output2_loss: 0.7248\n",
            "Epoch 83/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4809 - output1_accuracy: 0.7955 - output1_loss: 0.8096 - output2_accuracy: 0.8681 - output2_loss: 0.6712 - val_loss: 1.5915 - val_output1_accuracy: 0.7556 - val_output1_loss: 0.8725 - val_output2_accuracy: 0.8372 - val_output2_loss: 0.7190\n",
            "Epoch 84/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4850 - output1_accuracy: 0.7953 - output1_loss: 0.8121 - output2_accuracy: 0.8663 - output2_loss: 0.6729 - val_loss: 1.6288 - val_output1_accuracy: 0.7453 - val_output1_loss: 0.9066 - val_output2_accuracy: 0.8347 - val_output2_loss: 0.7222\n",
            "Epoch 85/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4853 - output1_accuracy: 0.7934 - output1_loss: 0.8068 - output2_accuracy: 0.8651 - output2_loss: 0.6785 - val_loss: 1.6094 - val_output1_accuracy: 0.7505 - val_output1_loss: 0.8891 - val_output2_accuracy: 0.8388 - val_output2_loss: 0.7203\n",
            "Epoch 86/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4743 - output1_accuracy: 0.7993 - output1_loss: 0.8005 - output2_accuracy: 0.8656 - output2_loss: 0.6738 - val_loss: 1.5873 - val_output1_accuracy: 0.7527 - val_output1_loss: 0.8726 - val_output2_accuracy: 0.8431 - val_output2_loss: 0.7147\n",
            "Epoch 87/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4742 - output1_accuracy: 0.7965 - output1_loss: 0.8085 - output2_accuracy: 0.8706 - output2_loss: 0.6657 - val_loss: 1.6117 - val_output1_accuracy: 0.7422 - val_output1_loss: 0.8952 - val_output2_accuracy: 0.8459 - val_output2_loss: 0.7166\n",
            "Epoch 88/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4671 - output1_accuracy: 0.8037 - output1_loss: 0.8000 - output2_accuracy: 0.8706 - output2_loss: 0.6672 - val_loss: 1.6083 - val_output1_accuracy: 0.7503 - val_output1_loss: 0.8915 - val_output2_accuracy: 0.8428 - val_output2_loss: 0.7168\n",
            "Epoch 89/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4716 - output1_accuracy: 0.7993 - output1_loss: 0.8025 - output2_accuracy: 0.8716 - output2_loss: 0.6691 - val_loss: 1.6125 - val_output1_accuracy: 0.7466 - val_output1_loss: 0.8928 - val_output2_accuracy: 0.8398 - val_output2_loss: 0.7197\n",
            "Epoch 90/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4768 - output1_accuracy: 0.7985 - output1_loss: 0.8028 - output2_accuracy: 0.8695 - output2_loss: 0.6740 - val_loss: 1.6015 - val_output1_accuracy: 0.7448 - val_output1_loss: 0.8914 - val_output2_accuracy: 0.8450 - val_output2_loss: 0.7101\n",
            "Epoch 91/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4679 - output1_accuracy: 0.8019 - output1_loss: 0.7957 - output2_accuracy: 0.8686 - output2_loss: 0.6722 - val_loss: 1.5970 - val_output1_accuracy: 0.7563 - val_output1_loss: 0.8775 - val_output2_accuracy: 0.8370 - val_output2_loss: 0.7195\n",
            "Epoch 92/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4689 - output1_accuracy: 0.7968 - output1_loss: 0.8046 - output2_accuracy: 0.8727 - output2_loss: 0.6643 - val_loss: 1.5914 - val_output1_accuracy: 0.7566 - val_output1_loss: 0.8798 - val_output2_accuracy: 0.8411 - val_output2_loss: 0.7117\n",
            "Epoch 93/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4680 - output1_accuracy: 0.7992 - output1_loss: 0.7967 - output2_accuracy: 0.8677 - output2_loss: 0.6713 - val_loss: 1.6100 - val_output1_accuracy: 0.7513 - val_output1_loss: 0.8841 - val_output2_accuracy: 0.8355 - val_output2_loss: 0.7258\n",
            "Epoch 94/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4752 - output1_accuracy: 0.7964 - output1_loss: 0.8054 - output2_accuracy: 0.8682 - output2_loss: 0.6698 - val_loss: 1.6012 - val_output1_accuracy: 0.7509 - val_output1_loss: 0.8918 - val_output2_accuracy: 0.8458 - val_output2_loss: 0.7094\n",
            "Epoch 95/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4657 - output1_accuracy: 0.8006 - output1_loss: 0.8015 - output2_accuracy: 0.8705 - output2_loss: 0.6642 - val_loss: 1.6006 - val_output1_accuracy: 0.7472 - val_output1_loss: 0.8914 - val_output2_accuracy: 0.8453 - val_output2_loss: 0.7092\n",
            "Epoch 96/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4673 - output1_accuracy: 0.8022 - output1_loss: 0.7983 - output2_accuracy: 0.8669 - output2_loss: 0.6690 - val_loss: 1.6019 - val_output1_accuracy: 0.7509 - val_output1_loss: 0.8834 - val_output2_accuracy: 0.8383 - val_output2_loss: 0.7185\n",
            "Epoch 97/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4803 - output1_accuracy: 0.7974 - output1_loss: 0.8038 - output2_accuracy: 0.8626 - output2_loss: 0.6765 - val_loss: 1.5842 - val_output1_accuracy: 0.7572 - val_output1_loss: 0.8709 - val_output2_accuracy: 0.8388 - val_output2_loss: 0.7133\n",
            "Epoch 98/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4696 - output1_accuracy: 0.8005 - output1_loss: 0.7997 - output2_accuracy: 0.8705 - output2_loss: 0.6698 - val_loss: 1.5894 - val_output1_accuracy: 0.7552 - val_output1_loss: 0.8754 - val_output2_accuracy: 0.8444 - val_output2_loss: 0.7141\n",
            "Epoch 99/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4595 - output1_accuracy: 0.8090 - output1_loss: 0.7922 - output2_accuracy: 0.8711 - output2_loss: 0.6674 - val_loss: 1.6023 - val_output1_accuracy: 0.7561 - val_output1_loss: 0.8706 - val_output2_accuracy: 0.8334 - val_output2_loss: 0.7317\n",
            "Epoch 100/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4612 - output1_accuracy: 0.7990 - output1_loss: 0.7966 - output2_accuracy: 0.8730 - output2_loss: 0.6647 - val_loss: 1.5939 - val_output1_accuracy: 0.7536 - val_output1_loss: 0.8796 - val_output2_accuracy: 0.8431 - val_output2_loss: 0.7144\n",
            "Epoch 101/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4640 - output1_accuracy: 0.7989 - output1_loss: 0.8018 - output2_accuracy: 0.8755 - output2_loss: 0.6622 - val_loss: 1.5756 - val_output1_accuracy: 0.7611 - val_output1_loss: 0.8698 - val_output2_accuracy: 0.8444 - val_output2_loss: 0.7058\n",
            "Epoch 102/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4606 - output1_accuracy: 0.8051 - output1_loss: 0.7947 - output2_accuracy: 0.8727 - output2_loss: 0.6659 - val_loss: 1.6066 - val_output1_accuracy: 0.7472 - val_output1_loss: 0.8900 - val_output2_accuracy: 0.8431 - val_output2_loss: 0.7167\n",
            "Epoch 103/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4661 - output1_accuracy: 0.7954 - output1_loss: 0.8084 - output2_accuracy: 0.8758 - output2_loss: 0.6576 - val_loss: 1.5939 - val_output1_accuracy: 0.7533 - val_output1_loss: 0.8776 - val_output2_accuracy: 0.8455 - val_output2_loss: 0.7163\n",
            "Epoch 104/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4581 - output1_accuracy: 0.8004 - output1_loss: 0.7945 - output2_accuracy: 0.8751 - output2_loss: 0.6636 - val_loss: 1.6034 - val_output1_accuracy: 0.7458 - val_output1_loss: 0.8926 - val_output2_accuracy: 0.8447 - val_output2_loss: 0.7108\n",
            "Epoch 105/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4592 - output1_accuracy: 0.8060 - output1_loss: 0.7968 - output2_accuracy: 0.8761 - output2_loss: 0.6623 - val_loss: 1.5746 - val_output1_accuracy: 0.7717 - val_output1_loss: 0.8547 - val_output2_accuracy: 0.8391 - val_output2_loss: 0.7199\n",
            "Epoch 106/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4735 - output1_accuracy: 0.8023 - output1_loss: 0.8014 - output2_accuracy: 0.8676 - output2_loss: 0.6721 - val_loss: 1.5933 - val_output1_accuracy: 0.7542 - val_output1_loss: 0.8795 - val_output2_accuracy: 0.8433 - val_output2_loss: 0.7138\n",
            "Epoch 107/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 34ms/step - loss: 1.4649 - output1_accuracy: 0.8017 - output1_loss: 0.7987 - output2_accuracy: 0.8686 - output2_loss: 0.6663 - val_loss: 1.6064 - val_output1_accuracy: 0.7548 - val_output1_loss: 0.8814 - val_output2_accuracy: 0.8364 - val_output2_loss: 0.7250\n",
            "Epoch 108/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4715 - output1_accuracy: 0.7982 - output1_loss: 0.8024 - output2_accuracy: 0.8710 - output2_loss: 0.6691 - val_loss: 1.5934 - val_output1_accuracy: 0.7603 - val_output1_loss: 0.8742 - val_output2_accuracy: 0.8381 - val_output2_loss: 0.7191\n",
            "Epoch 109/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4548 - output1_accuracy: 0.8045 - output1_loss: 0.7889 - output2_accuracy: 0.8725 - output2_loss: 0.6659 - val_loss: 1.6035 - val_output1_accuracy: 0.7489 - val_output1_loss: 0.8806 - val_output2_accuracy: 0.8375 - val_output2_loss: 0.7228\n",
            "Epoch 110/110\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 33ms/step - loss: 1.4647 - output1_accuracy: 0.7995 - output1_loss: 0.8013 - output2_accuracy: 0.8725 - output2_loss: 0.6633 - val_loss: 1.5780 - val_output1_accuracy: 0.7661 - val_output1_loss: 0.8596 - val_output2_accuracy: 0.8398 - val_output2_loss: 0.7185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "0uKPYCcg-upa",
        "outputId": "81765974-28e8-420a-d5ac-3f352018bc22"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model weights\n",
        "model.save_weights(\"enhanced_cnn_test.weights.h5\")"
      ],
      "metadata": {
        "id": "Ho4tOH05-xJt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model):\n",
        "    testgen = datagenerator(cifar10_x_test_1, cifar10_x_test_2, cifar10_y_test_1, cifar10_y_test_2, 10000)\n",
        "    eval_samples_x, eval_samples_y = next(testgen)\n",
        "    predictions = model.predict(eval_samples_x)\n",
        "    pred1 = np.argmax(predictions[0], axis=1)\n",
        "    pred2 = np.argmax(predictions[1], axis=1)\n",
        "    correct_guesses_1 = pred1 == np.argmax(eval_samples_y[0], axis=1)\n",
        "    correct_guesses_2 = pred2 == np.argmax(eval_samples_y[1], axis=1)\n",
        "    return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2)) / 2\n",
        "\n",
        "repeat_eval = 10\n",
        "eval_results = []\n",
        "for i in range(repeat_eval):\n",
        "    eval_results.append(eval_model(model))\n",
        "\n",
        "print(\"Mean accuracy =\", np.mean(eval_results))\n",
        "print(\"Standard deviation =\", np.std(eval_results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8zoeQSR-zv3",
        "outputId": "422d3045-f799-4d00-db1f-2ec3c3fcaf7b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Mean accuracy = 0.79357\n",
            "Standard deviation = 0.003169321693990679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vBADJtvxKPho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Create training and validation data generators\n",
        "train_gen = datagenerator(cifar10_x_train_1, cifar10_x_train_2, cifar10_y_train_1, cifar10_y_train_2, 64)\n",
        "val_gen = datagenerator(cifar10_x_val_1, cifar10_x_val_2, cifar10_y_val_1, cifar10_y_val_2, 64)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QjStOrLfMaNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Create the model\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "output1 = Dense(5, activation='softmax', name='output1')(x)\n",
        "output2 = Dense(5, activation='softmax', name='output2')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=[output1, output2])\n",
        "\n",
        "# Compile model\n",
        "epochs = 25  # Number of epochs\n",
        "lrate = 0.01\n",
        "decay = lrate / epochs\n",
        "sgd = SGD(learning_rate=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "steps_per_epoch = cifar10_x_train_1.shape[0] // 64\n",
        "validation_steps = cifar10_x_val_1.shape[0] // 64\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AOF-1xfVJ-l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Evaluate the model\n",
        "def eval_model(model):\n",
        "    testgen = datagenerator(cifar10_x_test_1, cifar10_x_test_2, cifar10_y_test_1, cifar10_y_test_2, 10000)\n",
        "    eval_samples_x, eval_samples_y = next(testgen)\n",
        "    predictions = model.predict(eval_samples_x)\n",
        "    pred1 = np.argmax(predictions[0], axis=1)\n",
        "    pred2 = np.argmax(predictions[1], axis=1)\n",
        "    correct_guesses_1 = pred1 == np.argmax(eval_samples_y[0], axis=1)\n",
        "    correct_guesses_2 = pred2 == np.argmax(eval_samples_y[1], axis=1)\n",
        "    return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2)) / 2\n",
        "\n",
        "repeat_eval = 10\n",
        "eval_results = []\n",
        "for i in range(repeat_eval):\n",
        "    eval_results.append(eval_model(model))\n",
        "\n",
        "print(\"Mean accuracy =\", np.mean(eval_results))\n",
        "print(\"Standard deviation =\", np.std(eval_results))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_4Hexlz2KI2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`Additional exploration and work:`** For fine-tuning the model Transfer learning can be applied"
      ],
      "metadata": {
        "id": "PZtfrUDU2DA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "mE72vHeUFI3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Resize CIFAR-10 images to match DenseNet121 input size\n",
        "resize_layer = layers.Lambda(lambda x: tf.image.resize(x, (224, 224)))\n",
        "\n",
        "# Build the transfer learning model with DenseNet121\n",
        "def build_model():\n",
        "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    inputs = layers.Input(shape=(32, 32, 3))\n",
        "    resized_inputs = resize_layer(inputs)\n",
        "    x = base_model(resized_inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Output branch for classes 0-4\n",
        "    x1 = layers.Dense(1024, activation='relu')(x)\n",
        "    x1 = layers.Dropout(0.2)(x1)\n",
        "    output1 = layers.Dense(5, activation='softmax', name='output1')(x1)\n",
        "\n",
        "    # Output branch for classes 5-9\n",
        "    x2 = layers.Dense(1024, activation='relu')(x)\n",
        "    x2 = layers.Dropout(0.2)(x2)\n",
        "    output2 = layers.Dense(5, activation='softmax', name='output2')(x2)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=[output1, output2])\n",
        "    return model\n",
        "\n",
        "# Instantiate the model\n",
        "model = build_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss={'output1': 'categorical_crossentropy', 'output2': 'categorical_crossentropy'},\n",
        "    metrics={'output1': 'accuracy', 'output2': 'accuracy'}\n",
        ")\n",
        "\n",
        "# Prepare data generators\n",
        "train_gen = datagenerator(cifar10_x_train[cifar10_y_train[:, 0] < 5],\n",
        "                          cifar10_x_train[cifar10_y_train[:, 0] >= 5],\n",
        "                          cifar10_y_train[cifar10_y_train[:, 0] < 5],\n",
        "                          cifar10_y_train[cifar10_y_train[:, 0] >= 5], 300)\n",
        "\n",
        "val_gen = datagenerator(cifar10_x_val[cifar10_y_val[:, 0] < 5],\n",
        "                        cifar10_x_val[cifar10_y_val[:, 0] >= 5],\n",
        "                        cifar10_y_val[cifar10_y_val[:, 0] < 5],\n",
        "                        cifar10_y_val[cifar10_y_val[:, 0] >= 5], 300)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=500,  # Define appropriate steps based on dataset size\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=100,\n",
        "    epochs=50,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"cifar10_densenet.h5\")\n",
        "\n",
        "# Define eval_model function for evaluation\n",
        "def eval_model(model):\n",
        "    testgen = datagenerator(cifar10_x_test_1, cifar10_x_test_2, cifar10_y_test_1, cifar10_y_test_2, 10000)\n",
        "    eval_samples_x, eval_samples_y = next(testgen)\n",
        "    predictions = model.predict(eval_samples_x)\n",
        "    pred1 = np.argmax(predictions[0], axis=1)\n",
        "    pred2 = np.argmax(predictions[1], axis=1)\n",
        "    correct_guesses_1 = pred1 == np.argmax(eval_samples_y[0], axis=1)\n",
        "    correct_guesses_2 = pred2 == np.argmax(eval_samples_y[1], axis=1)\n",
        "    return (np.mean(correct_guesses_1) + np.mean(correct_guesses_2)) / 2\n",
        "\n",
        "# Evaluate the model multiple times\n",
        "repeat_eval = 10\n",
        "eval_results = []\n",
        "\n",
        "for i in range(repeat_eval):\n",
        "    eval_results.append(eval_model(model))\n",
        "\n",
        "print(\"Mean accuracy =\", np.mean(eval_results))\n",
        "print(\"Standard deviation =\", np.std(eval_results))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "J2lVbWKc2B-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What to Submit\n",
        "\n",
        "As usual, you need to submit a single notebook that must be executable on Colab. The notebook should be properly commented and include a complete record of the training process, as well as the calculation of accuracy according to the guidelines provided above.\n",
        "\n",
        "# Good luck!\n",
        "\n"
      ],
      "metadata": {
        "id": "j1yTRAzn4i9g"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}